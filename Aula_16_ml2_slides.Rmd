---
output: 
  beamer_presentation:
    fig_caption: no
theme: "Boadilla"
colortheme: "whale"
---

![](/Users/jameshunter/Documents/UNIFESP/MAD-CB/course logo.png)


# Machine Learning -- 2

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.height = 3, fig.width = 5)
knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before) 
    return(options$size)
})
```

```{r loadmods, echo = FALSE}
  suppressMessages(library(tidyverse))
  suppressPackageStartupMessages(library(DescTools))
  suppressPackageStartupMessages(library(knitr))
  suppressPackageStartupMessages(library(caret))
  suppressPackageStartupMessages(library(mice))  ## novo pacote
  suppressPackageStartupMessages(library(corrr)) ## novo pacote
  suppressPackageStartupMessages(library(ROCR)) ## novo pacote
  suppressPackageStartupMessages(library(pROC)) ## novo pacote
  suppressPackageStartupMessages(library(rpart)) ## novo pacote
  suppressPackageStartupMessages(library(rpart.plot)) ## novo pacote
  suppressPackageStartupMessages(library(randomForest)) ## novo pacote
  suppressMessages(library(mosaic))
  options(scipen = 5)
```

## Machine Learning
  
  - Inteligência artificial ("AI")
  - Modelo orientado a dados
  - Algoritmos **aprendem** por treinamento com dados observados
  - E **prever casos desconhecidos**
  - Computadores de hoje capazes de tratar essas bases de dados
    - Mesmo laptops
  
## Machine Learning -- 2
![](/Users/jameshunter/Documents/UNIFESP/MAD-CB/ML_schema.png)

## ## Supervisionada -- Classificação vs. Regressão
![](/Users/jameshunter/Documents/UNIFESP/MAD-CB/sup_class_reg_2.png)

## Features -- Covariáveis

  - Variáveis para treinar o modelo
  - Selecionar as variáveis certas -- **crucial**
  - Mais features não necessariamente bom
    - Perigo de "overfitting"

## Overfitting
![](/Users/jameshunter/Documents/UNIFESP/MAD-CB/overfit_diag.png)

## Treinamento, Testes & Cross Validation 
![](/Users/jameshunter/Documents/UNIFESP/MAD-CB/cross_valid.png)

## Treinamento e Testes 

**NUNCA, JAMAIS, USE OS MESMOS DADOS PARA TESTES QUE VOCÊ USOU PARA TREINAMENTO**
  
## Cross-Validation (*k-fold*)

  - Uma de uma serie de técnicas usadas para fortalecer a capacidade do modelo para prever resultados
    - Bootstrap - reamostragem
  - Com os dados de treinamento só
  - Divide os dados em k grupos ("folds") aleatórios de tamanho igual
  - Construir o seu modelo usando todos fora de um grupo 
  - Testar o modelo nos dados no grupo que você reservou
    - Calcular o erro entre as previsões com o modelo e os valores observados
  - Repetir e fazer a média dos erros
  - O modelo (entre os k que você construiu) com a média menor é o modelo melhor

## Dados

  - Vêm de Wisconsin dados sobre câncer de mama
  - Características dos tumores de mama 
  - Variável dependente: diagnose (`diag`)

```{r loaddata, echo = FALSE, mysize=TRUE, size='\\tiny'}
bc_data <- read.table("breast-cancer-wisconsin-data.txt", 
                      header = FALSE,
                      sep = ",",
                      na.strings = "?")
colnames(bc_data) <- c("sample_code_number", 
                       "clump_thickness", 
                       "uniformity_of_cell_size", 
                       "uniformity_of_cell_shape", 
                       "marginal_adhesion", 
                       "single_epithelial_cell_size", 
                       "bare_nuclei", 
                       "bland_chromatin", 
                       "normal_nucleoli", 
                       "mitosis", 
                       "diag")

bc_data$diag <- ifelse(bc_data$diag == "2", "benign",
                          ifelse(bc_data$diag == "4", "malignant", NA))
bc_data[,2:10] <- apply(bc_data[, 2:10], 2, function(x) 
  X = as.numeric(as.character(x)))
dataset_impute <- mice(bc_data[, 2:10],  print = FALSE)
bc_data <- cbind(bc_data[, 11, drop = FALSE], mice::complete(dataset_impute, 1))
bc_data$diag <- as.factor(bc_data$diag)
```

## Dados

```{r dads, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
glimpse(bc_data)
```

## Gráfico das Diagnoses

```{r explorgr, echo = TRUE, eval = TRUE, mysize=TRUE, size='\\scriptsize' }
brgr1 <- ggplot(bc_data, aes(x = diag, fill = diag)) + geom_bar()
brgr1
```

## Gráfico das Covariáveis com a Diagnose

```{r cogr2, echo = FALSE, eval = TRUE}
gather(bc_data, x, y, clump_thickness:mitosis) %>%
  ggplot(aes(x = y, color = diag, fill = diag)) +
    geom_density(alpha = 0.3) +
    facet_wrap( ~ x, scales = "free", ncol = 3)
```

## Pacote `caret`

  - Funções para apoiar machine learning
  - Pode conduzir todo a análise dentro de `caret`
  - No grupos dos pacotes iniciais
  
## Separar Treinamento e Testes

  - Utilizar função `caret::createDataPartition()` para criar bases separadas
    - 1 para treinamento do modelo
    - 1 para testes
  - Especificar (`p`) porcentagem de dados colocado na base de treinamento
    - Entre 0.5 (50%) e 0.7 (70%)
  - `createDataPartition()` estratifica os dados baseada nas proporções da variável $y$
  
    
## Criar as Bases Treinamento e Testes

```{r ind, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
set.seed(42)
indice <- createDataPartition(bc_data$diag, p = 0.7, list = FALSE)
train_data <- bc_data[indice, ] # use os índices para o treinamento
test_data <- bc_data[-indice, ] # use os outros para testes
```

## Controle de Treinamento

  - Antes de iniciar o passo de treinar o modelos, precisamos decidir qual tipo de validação queremos usar
    - bootstrap, k-fold cross validation
  - Especificar através da função `caret::trainControl()`
  - Queremos usar *10-fold cross validation*
  - Se pudermos repetir o processo de cross validation, faz a seleção do modelo ainda mais forte
    - Repetiremos 10 vezes
  
## `trainControl()`

```{r cont, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
set.seed(42)
control <- trainControl(method = "repeatedcv",
                       number = 10,
                       repeats = 10,
                       savePredictions = TRUE,
                       verboseIter = FALSE)
```

## Treinamento do Modelo -- Regressão Logistica

```{r train, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
model_glm <- caret::train(diag ~ .,
                          data = train_data,
                          method = "glm",
                          preProcess = c("scale", "center"),
                          trControl = control)
```

## Objeto de Modelo

![model object](/Users/jameshunter/Documents/UNIFESP/MAD-CB/model_object.png)

  - R preserva todas as iterações do modelo
  - Objeto grande (1MB)

  
## Modelo

```{r mod, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
model_glm
```

## Resumo dos Resultados do Modelo

```{r mod2, echo = TRUE, mysize=TRUE, size='\\tiny'}
summary(model_glm)
```

## O Modelo Pode Predizer os Resultados de Treinamento e de Teste?

  - Função `predict()`
    - com modelo e valores para ser usados para previsão
  - Aplicado a base de `train` como exemplo
  - Mais interessante -- base de `test`
    - Modelo nunca viu esses dados antes
  - **Teste ácido**

## Previsões

```{r prev, echo = TRUE, mysize=TRUE, size='\\tiny'}
predtr <- predict(model_glm, train_data)
predtestglm <- predict(model_glm, test_data) 
prop.table(table(predtestglm))
prop.table(table(predtr))
```

## Quais Variáveis Têm Importância para o Modelo

```{r varfitgr1, echo = TRUE, mysize=TRUE, size='\\tiny'}
plot(caret::varImp(model_glm))
```

## Previsões com os Dados de Teste -- Matriz de Confusão

```{r cfm1, echo = TRUE, mysize=TRUE, size='\\tiny'}
confusionMatrix(predtestglm, test_data$diag)
```

## Previsões com os Dados de Treinamento -- Matriz de Confusão

```{r cfm2, echo = TRUE, mysize=TRUE, size='\\tiny'}
confusionMatrix(predtr, train_data$diag)
```

## "Receiver Operating Characteristic" (ROC) Validação do Modelo

  - Desenvolvido ao início da WWII para determinar o que foi o sinal recebido pela nova tecnologia, *radar*
    - Avião ou pássaro
  - Mede *sensibilidade* vs. *especificidade* de um modelo
  - *Sensibilidade* = % do resultado positivo correto
    - Teste mede % dos resultados positivos das pessoas com uma doença
    - Taxa de previsões positivas certas ("True positive rate", TPR)
  - *Especificidade* = % do resultado negativo correto
    - Teste mede % dos resultados negativos das pessoas sem uma doença
    - Taxa de previsões positivas erradas ("False positive rate", FPR)
    - Visualização da troca entre alta sensibilidade do modelo vs. alta especificidade
    - Não pode ter os 2 juntos
    
## AUC (Área abaixo da Curva)

  - AUC mede quanto porcentagem da área do gráfico a curva do modelo cobre
  - 100% quer dizer que o modelo é perfeitamente sensível e especifico
  - 50% quer dizer que o resultado é puramente aleatório
  - Modelos com AUC maiores prevêm melhor que eles com AUC menores
  - Pergunta:
    - Como calcular área abaixo de uma curva qualquer em matemática?
  
## ROC em R

  - 2 Pacotes
    - `pROC`
    - `ROCR`
  - Iguais (basicamente)
  - Começamos com `pROC`
    - Comando principal -- `roc`

## `pROC::roc()`

  - Compara as previsões contra as observações
  - Previsões precisam ser numéricas (não `factor`)
  - Use as opções seguintes:
    - `plot = TRUE, percent = TRUE, ci = TRUE, grid = TRUE`
  - Produz um gráfico e dados sobre o AUC

## Chamada e Estatísticas

```{r roctest, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
## colocar predtest na faixa de 0:1 (atualmente 1:2)
predtestroc <- as.numeric(predtestglm) -1
rocteste <- roc(response = test_data$diag, 
                predictor = predtestroc, 
                levels = c("benign", "malignant"), 
                plot = FALSE, percent = TRUE, 
                ci = TRUE, grid = TRUE)
rocteste
```

## Gráfico

```{r rocgr1, echo = FALSE }
plot(rocteste)
```

## Outra Curva ROC com Dados Mais Variáveis
![Curva ROC](/Users/jameshunter/Documents/UNIFESP/MAD-CB/rocex1.png)

## Procedimento com `ROCR`

- `ROCR` quer os dados num formato específico 
  - Precisa refazer a previsão utilizando a função deste pacote
  - Função usará uma versão numérica das previsões `predtest`
  - Depois calcular os valores da curva e fazer o gráfico
  - `ROCR` utiliza a terminologia "tpr" e "fpr" para gráfico ROC
  - Pode imprimir sensibilidade e especificidade com `sens`, `spec`
  
```{r rocrparam, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
## Fazer previsão do modelo com ROCR
ROCRpred <- prediction(as.numeric(predtestroc), test_data$diag)
ROCRperf <- performance(ROCRpred, "tpr", "fpr")
```

## Gráfico

```{r ROCRgr1, echo = FALSE}
plot(ROCRperf)
```

## Gráfico com Cores

```{r ROCRgr2, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
plot(ROCRperf, colorize = TRUE)
```

## Limites da Decisão sobre `diag`
  
  - Onde no gráfico fica a troca ótima?
    - No ponto mais para cima e para esquerda
  - `pROC::coords()` pode calcular este ponto
  - Precisa dar as seguintes informações a função:
    - nome de objeto de ROC
    - Palavra "best"
    - Coordenados para retornar a você ("threshold")

## Limites de Nosso Modelo

```{r lims, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
coords(rocteste, "best", ret = "threshold")
```

## Gráfico com Cores

```{r ROCRgr2a, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
plot(ROCRperf, colorize = TRUE)
```

## Novo Modelo -- Modelos de Arvore -- `rpart`

  - Modelos que constroem arvores de decisão
  - Excelentes para problemas de classificação
  - Pacote `rpart`
  - Gráficos mostra como escolha das classes está sendo feita
    - Gráfico vem do pacote `rpart.plot`

## Como Funciona uma Arvore

  - Cf. Kuhn & Johnson, *Applied Predictive Modeling* (2013)
  - Feita de *nodos* e *ramos*
  - Ramos conectam nodos até que chegar num nodo terminal
  - Algoritmo cria uma serie de partilhas (divisões) baseado em testes lógicos aninhados
  - Os testes lógicos definem a previsão que o modelo faria com novos dados
  
## Exemplo de uma Regra de uma Arvore

```
if Predictor A >= 1.7 then
|   if Predictor B >= 202.1 then Outcome = 1.3
|   else Outcome = 5.6
else Outcome 2.5
```

## Arvores São uma Técnica de Machine Learning Popular

  - Interpretação fácil
  - Podem lidar com muitas convariáveis de vários tipos
  - Não precisa descrever exatamente a relação entre
    - Variável dependente
    - Variáveis independentes
  - NA's não criam problemas
  - Mas, tem desvantagens também
    - São instáveis (pequena mudança numa variável pode cause grande mudança no resultado)
    - Exatidão de previsões não tão boa que outros tipos de modelos

## Funcionamento do Modelo de Arvore

  - Algoritmo divide os dados em grupos menores que são mais homogêneos com a dependente
  - 3 Critérios para divisão
    - Qual variável de previsão para usar para o "split"
    - Profundidade da arvore
    - A equação de previsão nos nodos terminais
  - Metodologia de `rpart` vem de Breiman et. al (1984)
    - Classification and regression tree (CART)
    
## Paramétros Chaves para `rpart`

  - `method`
    - Para classificação: "class"
    - Para regressão: "anova"
  - `control`
    - Vai chamar `rpart.control` explicito
    - `xval`: número de cross-validations
    - `minbucket`: número mínimo de observações em um nodo terminal
  - `parms` -- parâmetros para dividindo os casos
    - Só usado para classificação
    - `information`
    
## Vamos Construir Um Modelo de Câncer de Mama

```{r treemod, echo = TRUE, mysize=TRUE, size='\\footnotesize'}
set.seed(42)
fitree1 <- rpart(diag ~ .,
            data = train_data,
            method = "class",
            control = rpart.control(xval = 10, 
                                    minbucket = 2, 
                                    cp = 0), 
             parms = list(split = "information"))
```

## Arvore

```{r}
rpart.plot(fitree1, extra = 100)
```

## Resumo do Modelo de `rpart`

```{r summtree, echo = TRUE, mysize=TRUE, size='\\tiny'}
summary(fitree1, cp = 1)
```

## Splits com cp = 0.1
![Splits Arvore](/Users/jameshunter/Documents/UNIFESP/MAD-CB/cp1split.png)

## Previsões com a Arvore

```{r prevarv, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
predtesttr <- predict(fitree1, newdata = test_data, type = "class")
prop.table(table(predtesttr))
```

## Confusion Matrix -- Arvore

```{r cmarv, echo = TRUE, mysize=TRUE, size='\\tiny'}
confusionMatrix(predtesttr, test_data$diag)
```

## ROC Dados

```{r roctest2, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
## colocar predtest na faixa de 0:1 (atualmente 1:2)
predtesttrroc <- as.numeric(predtesttr) -1
rocteste <- roc(response = test_data$diag, 
                predictor = predtesttrroc, 
                levels = c("benign", "malignant"), 
                plot = FALSE, percent = TRUE, 
                ci = TRUE, grid = TRUE)
rocteste
suppressMessages(coords(rocteste, "best", ret = "threshold"))
```

## Gráfico

```{r rocgr2, echo = FALSE }
plot(rocteste)
```

## Arvores Mais Robustas -- Random Forests

  - Random Forests elaborado como algoritmo por Breiman em 2000
  - Ideia básica:  Combinando resultados de muitas arvores vai produzir uma arvore final melhor

> Grow many deep regression trees to randomized versions of the training data, and average them. *Efron & Hastie, 2016*

  - "Randomized versions" -- pode ser bootstrapping ou outras técnicas de re-amostragem
  
## Algoritmo de Random Forests
![Algoritmo - Random Forest](/Users/jameshunter/Documents/UNIFESP/MAD-CB/rfalgo.png)

Kuhn & Johnson (2013)

## Random Forests em R

  - Pacote `randomForest`
  - Formato:
  
```
randomForest(y ~ xvars, data = dados, ntrees = 1000, 
             importance = TRUE)
```
  - `y` deve ser expressa como `factor` para classificação
  - Argumentos chaves:
    - `ntrees`: número de arvores para a calcular; deve ser muito maior que o número das covariáveis 
    - `importance = TRUE`: para calcular os valores para importância dos variáveis
  
## Random Forests Aplicado ao Câncer de Mama

```{r rf, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
arvores = 100
rffit <- randomForest(as.factor(diag) ~ ., data = train_data, 
                      ntree = arvores, importance = TRUE, proximity = TRUE)
rffit
```

Confusion Matrix aqui é dos dados de *treinamento*

## OOB Error????

  - "Out of Bag"
    - Para todos as arvores, os erros associados com os valores não utilizados no treinamento do modelo
    - Como fizemos com cross-validation

## Previsões com a Random Forest

```{r prevrf, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
predtestrf <- predict(rffit, newdata = test_data, type = "class")
prop.table(table(predtestrf))
```
## Desempenho de Random Forest

```{r cmrf, echo = TRUE, mysize=TRUE, size='\\tiny'}
confusionMatrix(predtestrf, test_data$diag)
```

## Importância das Variáveis

```{r rfvarimp, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
randomForest::varImpPlot(rffit, type = 1)  ## NB, função dentro de randomForest
```

## O Que Quer Dizer "Mean Decrease Accuracy"

  -  Através de todos as arvores
    - A variável causa uma perda de precisão no modelo
  - Variáveis que podem causar perda de precisõ são mais importantes
  - Exemplos:
    - "bare nuclei" é a mais importante porque pode causar mais perda
    - "mitosis" é o menos importante, porque qualquer valor que assuma não vai afetar o resultado do modelo, `diag`

## Controle de Erros

  - Gráfico de redução de MSE com o número de arvores calculadas
  
```{r rfgr1,  echo = TRUE, mysize=TRUE, size='\\scriptsize'}
plot(rffit, log = 'y')
```

## Curva ROC e AUC para Random Forests

```{r roctest3, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
## colocar predtest na faixa de 0:1 (atualmente 1:2)
predtestrfroc <- as.numeric(predtestrf) -1
rocteste <- roc(response = test_data$diag, 
                predictor = predtestrfroc, 
                levels = c("benign", "malignant"), 
                plot = FALSE, percent = TRUE, 
                ci = TRUE, grid = TRUE)
rocteste
suppressMessages(coords(rocteste, "best", ret = "threshold"))
```

##

```{r rocgr3, echo = FALSE }
plot(rocteste)
```

## Fazer Random Forests com `caret`

  - Só precisa mudar o a especificação de `train` 
  - `method = "rf"`
  - `caret` chama `randomForest` para fazer os calculos
    - *wrapper* função
  - Aqui vamos fazer `set.seed(42)` para ser consistente com os outros métodos

## Calcular os Random Forests

```{r carrf, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
set.seed(42)
model_rf <- caret::train(diag ~ .,
                         data = train_data,
                         method = "rf",
                         preProcess = c("scale", "center"),
                         trControl = control)
```

## Resultados Básicos -- RF -- `caret`

```{r resmodrf, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
model_rf
```

## Calcular as Variáveis Importantes

```{r rfvarimp2,  echo = TRUE, mysize=TRUE, size='\\scriptsize'}
imp <- model_rf$finalModel$importance # Guarda em unidades originais
importance <- varImp(model_rf, scale = TRUE) # Scale coloca em escala de 100 -> 0
```

## Variáveis Importantes -- Escala Original

  - % das arvores em que a variável aparece (eu acho??)
```{r rfvarimp2a,  echo = TRUE, mysize=TRUE, size='\\scriptsize'}
imp[order(imp, decreasing = TRUE), ] 
```

## Variáveis Importantes - Escala 100 -> 0

```{r rfvarimp2b,  echo = TRUE, mysize=TRUE, size='\\scriptsize'}
importance
```

## Variáveis Importantes -- Gráfico

```{r rfvarimp2c,  echo = TRUE, mysize=TRUE, size='\\scriptsize'}
plot(importance)
```

## Previsões do Modelo de RF de `caret`

```{r rfpredcar, echo = TRUE, mysize=TRUE, size='\\tiny'}
predrfx <- predict(model_rf, test_data)
prop.table(table(predrfx))
```

## Matriz de Confusão -- Random Forest -- `caret`

```{r rfcfcar, echo = TRUE, mysize=TRUE, size='\\tiny'}
confusionMatrix(predrfx, test_data$diag)
```

## Previsões no Formato de Probabilidades

  - `type = "prob"` de `predict() põe os valores em probabilidades
  - Deixa você decidir qual seria o limite para diferenciar entre "benign" e "malignant"
    - Até agora, sempre foi 0.5

```{r rfpredprob, echo = TRUE, mysize=TRUE, size='\\tiny'}
results <- data.frame(actual = test_data$diag, predict(model_rf, test_data, type = "prob"))
results$prediction <- ifelse(results$benign > 0.5, "benign", 
                             ifelse(results$malignant > 0.5, "malignant", NA))
kable(head(results, 8))
```

## Acertamos com o Novo Modelo?

```{r rfpredtab, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
results$correct <- ifelse(results$actual == results$prediction, TRUE, FALSE)
prop.table(table(results$correct))
```

## Gráfico dos Resultados

```{r}
ggplot(results, aes(x = prediction, y = benign, color = correct, shape = correct)) +
  geom_jitter(size = 3, alpha = 0.6) + geom_hline(yintercept = 0.5) + 
  annotate("text", x = 2, y = 0.53, label = "Limite - 'threshold'")
```

## Este Gráfico Mostra

  - Erros de "benign"
    - Os 2 são perto a 0.50
  - Erros de "malignant"
    - Mais espalhadas 
    - Alguns com probabilidades bem perto a verdadeiro "malignant" (0.0)
  - Mais confiança nas previsões de "benign"
  - Parece que 0.5 é um bom "threshold" entre determinação de "benign" ou "malignant"
    - Discrimina bem

## Curva ROC e AUC para RF com `caret`

```{r roctestrfcar, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
## colocar predtest na faixa de 0:1 (atualmente 1:2)
predtestroc <- as.numeric(predrfx) -1
rocteste <- roc(response = test_data$diag, 
                predictor = predtestroc, 
                levels = c("benign", "malignant"), 
                plot = FALSE, percent = TRUE, 
                ci = TRUE, grid = TRUE)
rocteste
```

## Gráfico

```{r rocgrcarrf, echo = FALSE }
plot(rocteste)
```

## Comparação dos Métodos

```{r comp, echo = FALSE, mysize=TRUE, size='\\scriptsize'}
metodos <- data.frame(nomes = c("modelGLM", "rpart", "rf"),
                      acc = c(.9665, .9522, .9713),
                      kappa = c(.9261, .8934, .9369),
                      sens = rep(.9708, 3),
                      spec = c(.9583, .9167, .9722),
                      auc = c(.9646, .9437, .9715),
                      beg = c(.6507, .6651, .6459),
                      stringsAsFactors = FALSE)
metlong <- metodos %>% gather(tipo, valor, -nomes)
kable(metodos, caption = "Comparação de Precisão de 3 Modelos")
```

## Gráfico de Comparação

```{r compgr, echo = TRUE, mysize=TRUE, size='\\scriptsize'}
ordem <- c("acc", "kappa", "auc", "sens", "spec", "beg")
labs <- c("Precisão", "Kappa", "AUC", "Sensibilidade", "Especificidade", "Benigno")
grcomp <- ggplot(metlong, aes(x = tipo, y = valor, fill = nomes)) 
grcomp <- grcomp + geom_bar(stat = "identity", position = "dodge")
grcomp <- grcomp + coord_cartesian(ylim = c(.6, 1))
grcomp <- grcomp + scale_x_discrete(limits = ordem,
                                    labels = labs)
grcomp <- grcomp + theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))
grcomp <- grcomp + labs(title = "Comparação dos Algoritmos de Machine Learning",
                        x = "Medida", y = "Valor", fill = "Algoritmo")
grcomp <- grcomp + scale_fill_discrete(labels = c("Log. Regressão", 
                                                  "Random Forests",
                                                  "Arvores"))
```

##

```{r}
grcomp
```



## Tópicos para Semana que Vem

  - Machine Learning Não-Superivisionado
    - Cluster Analysis





